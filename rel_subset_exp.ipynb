{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA601"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joshua Black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring rel subset with text analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The philosophy subset is the collection of all documents in the corpus containing matches with the regex pattern 'philoso*'. \n",
    "\n",
    "This document will use concordancing, collocation, and cooccurance to develop a sense of how the word 'philosophy' appears in the corpus and to pick out other related terms which may be useful for picking out philosophical writing from the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import logging\n",
    "from random import sample\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaMulticore, TfidfModel\n",
    "from gensim.matutils import corpus2csc\n",
    "\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.corpus import stopwords, words\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_cytoscape as cyto\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "import NL_helpers\n",
    "import NL_topicmodels # Will need to generate BOW using function in topic models.\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "TOKENIZER = RegexpTokenizer(r\"[A-Za-z']+\")\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "WORDS = set(words.words()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell to reload NL_helpers and NL_topicmodels if they have been changed.\n",
    "from importlib import reload\n",
    "reload(NL_helpers)\n",
    "reload(NL_topicmodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have already generated a dataset containing all articles with the regex search term 'philoso*' run on the NL library. I load it as follows:\n",
    "\n",
    "**Note, error:** the step at which I apply the search is before the text has been converted to lower case. The results of the re search are case sensitive. I had intended to include, e.g. 'Philosophy' as well. I don't expect that this will cause too many problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "philoso_df = pd.read_pickle('pickles/rel_v2_philoso_df.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "philoso_df['Tokenised'] = philoso_df['Text'].apply(\n",
    "    lambda x: TOKENIZER.tokenize(' '.join(x).lower())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates ought to be removed from 'subset' corpus, but have already been removed from full 'philoso*' corpus.\n",
    "# philoso_df = philoso_df[~philoso_df.astype(str).duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ODT        1163\n",
       "ESD        1064\n",
       "AS          879\n",
       "OW          869\n",
       "CHP         558\n",
       "LT          467\n",
       "NZTIM       425\n",
       "BH          391\n",
       "TC          344\n",
       "HBH         320\n",
       "NEM         298\n",
       "WC          263\n",
       "WH          242\n",
       "DSC         234\n",
       "NOT         226\n",
       "OAM         221\n",
       "DTN         211\n",
       "MEX         158\n",
       "WCT         138\n",
       "WT          124\n",
       "GRA         119\n",
       "WSTAR       116\n",
       "AG          110\n",
       "CROMARG      90\n",
       "LWM          89\n",
       "MIC          85\n",
       "WI           75\n",
       "ME           75\n",
       "FS           73\n",
       "DUNST        58\n",
       "WDT          53\n",
       "WAIST        48\n",
       "MT           38\n",
       "MS           38\n",
       "OO           37\n",
       "WEST         32\n",
       "WOODEX       31\n",
       "IT           30\n",
       "LCP          30\n",
       "MH           30\n",
       "HNS          28\n",
       "BA           26\n",
       "NA           21\n",
       "CL           20\n",
       "HBT          18\n",
       "KUMAT        14\n",
       "OG            8\n",
       "HAST          7\n",
       "OPUNT         7\n",
       "NZSCSG        4\n",
       "HLC           3\n",
       "NZCPNA        1\n",
       "HBWT          1\n",
       "WDA           1\n",
       "MTBM          1\n",
       "ALG           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts by newspaper\n",
    "philoso_df.index.map(lambda x: x[0:x.find('_')]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows that we have 29575 items containing 'philoso\\*' in the whole dataset. This is between two and three times the size of the 'starter corpus', but is significantly smaller than the total corpus. **TODO: put full size here.**\n",
    "\n",
    "I've also produced a count for each newspaper. OW - the Otago Witness tops the list. Surprising as this was a weekly paper and so should be expected to have less total issues than the others. However, it might have had more 'intellectual' content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3c37fa87d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Counts by year.\n",
    "philoso_df.index.map(lambda x: int(x[x.find('_')+1:x.find('_')+5])).to_series().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting a subset of the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at a random subset of the corpus as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = sample(list(philoso_df.index), 100)\n",
    "interact(NL_helpers.html_text, index=sample_indices, dataframe=fixed(philoso_df), boldface=fixed('philoso*\\\\w*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few notes: * (Note your random sample will be different)\n",
    " - AS_18860821_ARTICLE40: Example of argument with 'freethinker' over grouding ethics(?) in 'natural right' vs Christian approach. Interesting as lower limit in terms of OCR quality?\n",
    " - Use of 'philosophical' to mean deep, resigned, detatched.\n",
    " - 'philosophers and sceptics' vs Christians.\n",
    " - CHP_18980425_ARTICLE60: Report of what is issued at the wellington public library in 1898 - 'philosophical subjects are almost entire;y neglected'\n",
    " - Discussion of Darwinism as new philosophy.\n",
    " - Discussions of e.g. Stoicism.\n",
    " - 1893 Hosking on Miricles, listed as 'popular lecture'. CHP_18930515_ARTICLE22\n",
    " - **In general, quite a few reprints of exerpts from texts. (e.g. BH_18890222_ARTICLE33)\n",
    " - Robert Stout comes up a lot as an early political figure who is thought of as having, e.g. 'a philosophic mind'.\n",
    " - Some lecture reports coming through (e.g. AS_18800817_ARTICLE22, CHP_18690823_ARTICLE15)\n",
    " - Theosophy coming through\n",
    " - Quite a lot of extracts of fiction (one with a Hegelian character).\n",
    " - CL_18790919_ARTICLE27 - first-order philosophy - including definition of 'philosophy' in Clutha Leader.\n",
    " - CHP_18920926_ARTICLE10 - good letters to editor on 'freethought' and christianity\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concordancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by quickly looking through concordances for key words. The initial 'flat list' of tokens is taken from a random sample of 1000 items in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = []\n",
    "for tokens in philoso_df['Tokenised'].sample(n=1000, random_state=1):\n",
    "    for token in tokens:\n",
    "        flat_list.append(token)\n",
    "sample_text = Text(flat_list)\n",
    "del flat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook keeps the full dataset in memory. I'll be using 'del' to remove references to large objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up, 'philosophy':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text.concordance('philosophy', width=100, lines=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notable:\n",
    " - discussion of 'natural philosophy' and 'experimental philosophy' - what would today be called 'science'.\n",
    " - generic use of 'philosophy' as 'way of thinking'\n",
    " - philosophy as 'extravagant theories'\n",
    " - Quite a few descriptions of people 'aquire his graveful pedantry his philosophy his ripe wisdom' which sound like descriptions in a Victorian novel... There is quite a bit of serialised fiction in the general corpus.\n",
    " - some discussion of academic situations (classrooms etc)\n",
    "  - mention of particular philosophers both ancient and contemp (Plato, the stoics, Descartes, Spencer, Carlyle)\n",
    "  - Ambiguous relationship with theology. \n",
    "  - NZ figures: e.g. Robert Stout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_text.concordance('lecture', width=100, lines=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sample_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocations shows which words have a tendency to appear together *near one another* in documents (cf. co-occurrence). The ranking of word pairs depends on the statistic chosen.\n",
    "\n",
    "**PMI:** pointwise mutual information is a measure from information theory. Suppose we have probability distributions for each word, *x* and *y*, we might wonder how much information about p(x) is carried by p(y). If the words *x* and *y* always occur together, then *pmi* will be very high. This makes PMI a good measure of word occurence (dreadful - come back once you've reminded yourself how this works).\n",
    "\n",
    "**Likelihood ratio:**\n",
    "\n",
    "The code below collects all immediate bigrams for a window of size 2 and of size 5. We then filter our bigrams which do not contain 'philosophy', those which appear less than three times, and those which contain stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again build up a flat list, but this time with the whole corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = []\n",
    "for tokens in philoso_df['Tokenised']:\n",
    "    for token in tokens:\n",
    "        flat_list.append(token)\n",
    "all_text = Text(flat_list)\n",
    "del flat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Window size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "philoso_filter = lambda *w: 'philosophy' not in w\n",
    "stopword_filter = lambda w: w in STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcf = BigramCollocationFinder.from_words(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcf.apply_ngram_filter(philoso_filter)\n",
    "bcf.apply_word_filter(stopword_filter)\n",
    "bcf.apply_freq_filter(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_ws2 = bcf.nbest(bm.pmi, 50)\n",
    "pmi_ws2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a window size of two, we get words either side of 'philosophy'.\n",
    "Notes:\n",
    " - natural comes up again, along with 'experimental', 'positive', 'inductive'. \n",
    " - 'pig philosophy' is, I think, a term of Carylye's - suggest some specific discussions.\n",
    " - most suggest intellectual discussion (except maybe 'proverbial'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ws2 = bcf.nbest(bm.likelihood_ratio, 50)\n",
    "lr_ws2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_not_lr = []\n",
    "for collocation in pmi_ws2:\n",
    "    if collocation not in lr_ws2:\n",
    "        pmi_not_lr.append(collocation)\n",
    "pmi_not_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_not_pmi = []\n",
    "for collocation in lr_ws2:\n",
    "    if collocation not in pmi_ws2:\n",
    "        lr_not_pmi.append(collocation)\n",
    "lr_not_pmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences here don't seem to make a big difference to the conclusions above. Not surprising as they are very closely related measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bcf\n",
    "del all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Window size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also expand the window to consider words either five spaces to the left or right of philosophy. (Window size includes stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcf_big = BigramCollocationFinder.from_words(all_text, window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcf_big.apply_ngram_filter(philoso_filter)\n",
    "bcf_big.apply_word_filter(stopword_filter)\n",
    "bcf_big.apply_freq_filter(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_ws5 = bcf_big.nbest(bm.pmi, 50)\n",
    "pmi_ws5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general impression of these collocations is quite similar to those with window size two. \n",
    "Notes:\n",
    " - I've noticed 'there are more things in heaven and earth than dreamt ...' a few times while looking through the corpus. I supsect ('dreamt', 'philosophy') comes from this.\n",
    " - There's more evidence of 'natural philosophy' etc. We also get 'mental philosophy' something like psychology.\n",
    " - Discussion of Herbert Spencer coming through also.\n",
    " - In general: evidence of intellectual content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr_ws5 = bcf_big.nbest(bm.likelihood_ratio, 50)\n",
    "lr_ws5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_not_lr_ws5 = []\n",
    "for collocation in pmi_ws5:\n",
    "    if collocation not in lr_ws5:\n",
    "        pmi_not_lr_ws5.append(collocation)\n",
    "pmi_not_lr_ws5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_not_pmi_ws5 = []\n",
    "for collocation in lr_ws5:\n",
    "    if collocation not in pmi_ws5:\n",
    "        lr_not_pmi_ws5.append(collocation)\n",
    "lr_not_pmi_ws5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More difference in results here (more ngrams to choose between). But neither list gives a particularly different impression of the corpus as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lr_not_pmi_ws5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bcf_big, all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences in scoring more pronounced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Co-occurence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform document-level cooccurence analysis we will shift from NLTK to gensim. We first build a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-25 10:58:03,524 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-01-25 10:58:09,882 : INFO : adding document #10000 to Dictionary(257722 unique tokens: [\"'\", 'a', 'aa', 'about', 'above']...)\n",
      "2021-01-25 10:58:09,998 : INFO : built Dictionary(262787 unique tokens: [\"'\", 'a', 'aa', 'about', 'above']...) from 10146 documents (total 7718025 corpus positions)\n",
      "2021-01-25 10:58:10,338 : INFO : discarding 239685 tokens: [(\"'\", 5711), ('a', 10043), ('agerf', 1), ('all', 7956), ('amoebae', 2), ('an', 7713), ('and', 10115), ('any', 5746), ('archmopteryx', 1), ('are', 7487)]...\n",
      "2021-01-25 10:58:10,338 : INFO : keeping 23102 tokens which were in no less than 10 and no more than 5073 (=50.0%) documents\n",
      "2021-01-25 10:58:10,419 : INFO : resulting dictionary: Dictionary(23102 unique tokens: ['aa', 'about', 'above', 'accomplished', 'accordingly']...)\n"
     ]
    }
   ],
   "source": [
    "minimum_in_docs = 10 # 10\n",
    "max_prop = 0.5\n",
    "dictionary = corpora.Dictionary(philoso_df['Tokenised'])\n",
    "dictionary.filter_extremes(no_below=minimum_in_docs, no_above=max_prop)\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-27 09:59:43,736 : INFO : saving Dictionary object under dictionaries/rel_v2_df_min10_max10perc.dict, separately None\n",
      "2021-01-27 09:59:43,742 : INFO : saved dictionaries/rel_v2_df_min10_max10perc.dict\n"
     ]
    }
   ],
   "source": [
    "dictionary.save(f'dictionaries/rel_v2_df_min{minimum_in_docs}_max{int(max_prop*100)}perc.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary is much too large for our purposes (at ~70k words). We can filter stop words and all one and two letter words from the tokenized text to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "philoso_df['Tokenised'] = philoso_df['Tokenised'].map(lambda x: [word for word in x if len(word)>2 and not word in STOPWORDS and word in WORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-27 09:59:18,143 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-01-27 09:59:20,810 : INFO : adding document #10000 to Dictionary(29041 unique tokens: ['accomplished', 'accordingly', 'account', 'act', 'actual']...)\n",
      "2021-01-27 09:59:20,815 : INFO : built Dictionary(29053 unique tokens: ['accomplished', 'accordingly', 'account', 'act', 'actual']...) from 10013 documents (total 2529106 corpus positions)\n",
      "2021-01-27 09:59:20,893 : INFO : discarding 17460 tokens: [('account', 1348), ('although', 1257), ('amoebae', 2), ('another', 2757), ('anything', 1545), ('appear', 1134), ('away', 1801), ('believe', 2943), ('came', 1551), ('cannot', 2974)]...\n",
      "2021-01-27 09:59:20,894 : INFO : keeping 11593 tokens which were in no less than 10 and no more than 1001 (=10.0%) documents\n",
      "2021-01-27 09:59:20,911 : INFO : resulting dictionary: Dictionary(11593 unique tokens: ['accomplished', 'accordingly', 'act', 'actual', 'ail']...)\n"
     ]
    }
   ],
   "source": [
    "minimum_in_docs = 10 # reduced to 10 from 50 as corpus has got much smaller.\n",
    "max_prop = 0.1\n",
    "dictionary = corpora.Dictionary(philoso_df['Tokenised'])\n",
    "dictionary.filter_extremes(no_below=minimum_in_docs, no_above=max_prop)\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_corpus = NL_topicmodels.NL_corpus(philoso_df, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-27 10:00:26,952 : WARNING : constructor received both corpus and explicit inverse document frequencies; ignoring the corpus\n"
     ]
    }
   ],
   "source": [
    "tfidf_model = TfidfModel(rel_corpus, dictionary=rel_corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text as String</th>\n",
       "      <th>Religion (pred)</th>\n",
       "      <th>Tokenised</th>\n",
       "      <th>BOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LT_18940109_ARTICLE7</th>\n",
       "      <td>THE TASK OF THE BIOLOGIST.</td>\n",
       "      <td>[No. 11. When chemistry had finished _ shaping...</td>\n",
       "      <td>LT</td>\n",
       "      <td>18940109</td>\n",
       "      <td>No. 11. When chemistry had finished _ shaping;...</td>\n",
       "      <td>True</td>\n",
       "      <td>[chemistry, finished, shaping, stuff, physical...</td>\n",
       "      <td>[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT_18940115_ARTICLE5</th>\n",
       "      <td>THE THEORY OF EVOLUTION.</td>\n",
       "      <td>[SIGNIFICANT RUDIMENTS. [BY W.G.P.] No. lII.' ...</td>\n",
       "      <td>LT</td>\n",
       "      <td>18940115</td>\n",
       "      <td>SIGNIFICANT RUDIMENTS. [BY W.G.P.] No. lII.' '...</td>\n",
       "      <td>True</td>\n",
       "      <td>[significant, consideration, various, evidence...</td>\n",
       "      <td>[(1, 1), (7, 2), (17, 1), (24, 1), (31, 1), (3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT_18940129_ARTICLE48</th>\n",
       "      <td>THE THEORY OF EVOLUTION.</td>\n",
       "      <td>[A CHANGED WORLD. [BY W.G.P.] No. V. The bitte...</td>\n",
       "      <td>LT</td>\n",
       "      <td>18940129</td>\n",
       "      <td>A CHANGED WORLD. [BY W.G.P.] No. V. The bitter...</td>\n",
       "      <td>True</td>\n",
       "      <td>[world, bitter, controversy, rang, round, orig...</td>\n",
       "      <td>[(3, 1), (4, 1), (6, 1), (12, 1), (18, 1), (23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT_18940219_ARTICLE18</th>\n",
       "      <td>HERESY.</td>\n",
       "      <td>[TO THE EDITOR. Sir,— The action of the Presby...</td>\n",
       "      <td>LT</td>\n",
       "      <td>18940219</td>\n",
       "      <td>TO THE EDITOR. Sir,— The action of the Presbyt...</td>\n",
       "      <td>True</td>\n",
       "      <td>[editor, sir, action, assembly, rev, exercise,...</td>\n",
       "      <td>[(70, 1), (84, 2), (96, 2), (342, 1), (391, 1)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT_18940219_ARTICLE24</th>\n",
       "      <td>REV JAMES GIBB ON CHRISTIAN DUTY.</td>\n",
       "      <td>[At St Andrew’s Presbyterian Church, yesterday...</td>\n",
       "      <td>LT</td>\n",
       "      <td>18940219</td>\n",
       "      <td>At St Andrew’s Presbyterian Church, yesterday ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[church, yesterday, forenoon, rev, one, church...</td>\n",
       "      <td>[(69, 1), (70, 1), (83, 1), (84, 2), (85, 1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ODT_18771031_ARTICLE30</th>\n",
       "      <td>THE INDIAN FAMINE.</td>\n",
       "      <td>[TO THE TJDITOR. Sir—l think I have_ fair caus...</td>\n",
       "      <td>ODT</td>\n",
       "      <td>18771031</td>\n",
       "      <td>TO THE TJDITOR. Sir—l think I have_ fair cause...</td>\n",
       "      <td>True</td>\n",
       "      <td>[sir, think, fair, cause, complaint, matter, d...</td>\n",
       "      <td>[(21, 1), (53, 1), (147, 1), (274, 1), (276, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ODT_18771107_ARTICLE32</th>\n",
       "      <td>POPULAR CULTURE.</td>\n",
       "      <td>[The. discourse of Mi* J^hn M &gt;r!ev on \" I'opu...</td>\n",
       "      <td>ODT</td>\n",
       "      <td>18771107</td>\n",
       "      <td>The. discourse of Mi* J^hn M &gt;r!ev on \" I'opul...</td>\n",
       "      <td>True</td>\n",
       "      <td>[discourse, urn, special, pro, method, cation,...</td>\n",
       "      <td>[(76, 1), (208, 1), (245, 1), (332, 1), (348, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ODT_18790115_ARTICLE20</th>\n",
       "      <td>MR BRIGHT AND THE ELDERS. TO THE EDITOR.</td>\n",
       "      <td>[Sib,—However objectionable Mr Bright's title ...</td>\n",
       "      <td>ODT</td>\n",
       "      <td>18790115</td>\n",
       "      <td>Sib,—However objectionable Mr Bright's title m...</td>\n",
       "      <td>True</td>\n",
       "      <td>[sib, however, objectionable, title, may, subs...</td>\n",
       "      <td>[(59, 1), (125, 1), (221, 1), (369, 1), (469, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ODT_18790118_ARTICLE23</th>\n",
       "      <td>UNTITLED</td>\n",
       "      <td>[Sir,—Before the public can fairly under stand...</td>\n",
       "      <td>ODT</td>\n",
       "      <td>18790118</td>\n",
       "      <td>Sir,—Before the public can fairly under stand ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[sir, public, fairly, stand, position, taken, ...</td>\n",
       "      <td>[(27, 1), (49, 1), (50, 1), (81, 1), (116, 1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ODT_18790121_ARTICLE17</th>\n",
       "      <td>THE BIBLE SCHOOLS. TO THE EDITOR.</td>\n",
       "      <td>[Sia,—lt may not be out of place, in the prese...</td>\n",
       "      <td>ODT</td>\n",
       "      <td>18790121</td>\n",
       "      <td>Sia,—lt may not be out of place, in the presen...</td>\n",
       "      <td>True</td>\n",
       "      <td>[may, place, present, respecting, give, man, c...</td>\n",
       "      <td>[(8, 1), (57, 1), (71, 1), (276, 1), (505, 1),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10013 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           Title  \\\n",
       "LT_18940109_ARTICLE7                  THE TASK OF THE BIOLOGIST.   \n",
       "LT_18940115_ARTICLE5                    THE THEORY OF EVOLUTION.   \n",
       "LT_18940129_ARTICLE48                   THE THEORY OF EVOLUTION.   \n",
       "LT_18940219_ARTICLE18                                    HERESY.   \n",
       "LT_18940219_ARTICLE24          REV JAMES GIBB ON CHRISTIAN DUTY.   \n",
       "...                                                          ...   \n",
       "ODT_18771031_ARTICLE30                        THE INDIAN FAMINE.   \n",
       "ODT_18771107_ARTICLE32                          POPULAR CULTURE.   \n",
       "ODT_18790115_ARTICLE20  MR BRIGHT AND THE ELDERS. TO THE EDITOR.   \n",
       "ODT_18790118_ARTICLE23                                  UNTITLED   \n",
       "ODT_18790121_ARTICLE17         THE BIBLE SCHOOLS. TO THE EDITOR.   \n",
       "\n",
       "                                                                     Text  \\\n",
       "LT_18940109_ARTICLE7    [No. 11. When chemistry had finished _ shaping...   \n",
       "LT_18940115_ARTICLE5    [SIGNIFICANT RUDIMENTS. [BY W.G.P.] No. lII.' ...   \n",
       "LT_18940129_ARTICLE48   [A CHANGED WORLD. [BY W.G.P.] No. V. The bitte...   \n",
       "LT_18940219_ARTICLE18   [TO THE EDITOR. Sir,— The action of the Presby...   \n",
       "LT_18940219_ARTICLE24   [At St Andrew’s Presbyterian Church, yesterday...   \n",
       "...                                                                   ...   \n",
       "ODT_18771031_ARTICLE30  [TO THE TJDITOR. Sir—l think I have_ fair caus...   \n",
       "ODT_18771107_ARTICLE32  [The. discourse of Mi* J^hn M >r!ev on \" I'opu...   \n",
       "ODT_18790115_ARTICLE20  [Sib,—However objectionable Mr Bright's title ...   \n",
       "ODT_18790118_ARTICLE23  [Sir,—Before the public can fairly under stand...   \n",
       "ODT_18790121_ARTICLE17  [Sia,—lt may not be out of place, in the prese...   \n",
       "\n",
       "                       Newspaper      Date  \\\n",
       "LT_18940109_ARTICLE7          LT  18940109   \n",
       "LT_18940115_ARTICLE5          LT  18940115   \n",
       "LT_18940129_ARTICLE48         LT  18940129   \n",
       "LT_18940219_ARTICLE18         LT  18940219   \n",
       "LT_18940219_ARTICLE24         LT  18940219   \n",
       "...                          ...       ...   \n",
       "ODT_18771031_ARTICLE30       ODT  18771031   \n",
       "ODT_18771107_ARTICLE32       ODT  18771107   \n",
       "ODT_18790115_ARTICLE20       ODT  18790115   \n",
       "ODT_18790118_ARTICLE23       ODT  18790118   \n",
       "ODT_18790121_ARTICLE17       ODT  18790121   \n",
       "\n",
       "                                                           Text as String  \\\n",
       "LT_18940109_ARTICLE7    No. 11. When chemistry had finished _ shaping;...   \n",
       "LT_18940115_ARTICLE5    SIGNIFICANT RUDIMENTS. [BY W.G.P.] No. lII.' '...   \n",
       "LT_18940129_ARTICLE48   A CHANGED WORLD. [BY W.G.P.] No. V. The bitter...   \n",
       "LT_18940219_ARTICLE18   TO THE EDITOR. Sir,— The action of the Presbyt...   \n",
       "LT_18940219_ARTICLE24   At St Andrew’s Presbyterian Church, yesterday ...   \n",
       "...                                                                   ...   \n",
       "ODT_18771031_ARTICLE30  TO THE TJDITOR. Sir—l think I have_ fair cause...   \n",
       "ODT_18771107_ARTICLE32  The. discourse of Mi* J^hn M >r!ev on \" I'opul...   \n",
       "ODT_18790115_ARTICLE20  Sib,—However objectionable Mr Bright's title m...   \n",
       "ODT_18790118_ARTICLE23  Sir,—Before the public can fairly under stand ...   \n",
       "ODT_18790121_ARTICLE17  Sia,—lt may not be out of place, in the presen...   \n",
       "\n",
       "                        Religion (pred)  \\\n",
       "LT_18940109_ARTICLE7               True   \n",
       "LT_18940115_ARTICLE5               True   \n",
       "LT_18940129_ARTICLE48              True   \n",
       "LT_18940219_ARTICLE18              True   \n",
       "LT_18940219_ARTICLE24              True   \n",
       "...                                 ...   \n",
       "ODT_18771031_ARTICLE30             True   \n",
       "ODT_18771107_ARTICLE32             True   \n",
       "ODT_18790115_ARTICLE20             True   \n",
       "ODT_18790118_ARTICLE23             True   \n",
       "ODT_18790121_ARTICLE17             True   \n",
       "\n",
       "                                                                Tokenised  \\\n",
       "LT_18940109_ARTICLE7    [chemistry, finished, shaping, stuff, physical...   \n",
       "LT_18940115_ARTICLE5    [significant, consideration, various, evidence...   \n",
       "LT_18940129_ARTICLE48   [world, bitter, controversy, rang, round, orig...   \n",
       "LT_18940219_ARTICLE18   [editor, sir, action, assembly, rev, exercise,...   \n",
       "LT_18940219_ARTICLE24   [church, yesterday, forenoon, rev, one, church...   \n",
       "...                                                                   ...   \n",
       "ODT_18771031_ARTICLE30  [sir, think, fair, cause, complaint, matter, d...   \n",
       "ODT_18771107_ARTICLE32  [discourse, urn, special, pro, method, cation,...   \n",
       "ODT_18790115_ARTICLE20  [sib, however, objectionable, title, may, subs...   \n",
       "ODT_18790118_ARTICLE23  [sir, public, fairly, stand, position, taken, ...   \n",
       "ODT_18790121_ARTICLE17  [may, place, present, respecting, give, man, c...   \n",
       "\n",
       "                                                                      BOW  \n",
       "LT_18940109_ARTICLE7    [(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1...  \n",
       "LT_18940115_ARTICLE5    [(1, 1), (7, 2), (17, 1), (24, 1), (31, 1), (3...  \n",
       "LT_18940129_ARTICLE48   [(3, 1), (4, 1), (6, 1), (12, 1), (18, 1), (23...  \n",
       "LT_18940219_ARTICLE18   [(70, 1), (84, 2), (96, 2), (342, 1), (391, 1)...  \n",
       "LT_18940219_ARTICLE24   [(69, 1), (70, 1), (83, 1), (84, 2), (85, 1), ...  \n",
       "...                                                                   ...  \n",
       "ODT_18771031_ARTICLE30  [(21, 1), (53, 1), (147, 1), (274, 1), (276, 1...  \n",
       "ODT_18771107_ARTICLE32  [(76, 1), (208, 1), (245, 1), (332, 1), (348, ...  \n",
       "ODT_18790115_ARTICLE20  [(59, 1), (125, 1), (221, 1), (369, 1), (469, ...  \n",
       "ODT_18790118_ARTICLE23  [(27, 1), (49, 1), (50, 1), (81, 1), (116, 1),...  \n",
       "ODT_18790121_ARTICLE17  [(8, 1), (57, 1), (71, 1), (276, 1), (505, 1),...  \n",
       "\n",
       "[10013 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_corpus.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_corpus.items['TF-IDF'] = tfidf_model[rel_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text as String</th>\n",
       "      <th>Religion (pred)</th>\n",
       "      <th>Tokenised</th>\n",
       "      <th>BOW</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LT_18940109_ARTICLE7</th>\n",
       "      <td>THE TASK OF THE BIOLOGIST.</td>\n",
       "      <td>[No. 11. When chemistry had finished _ shaping...</td>\n",
       "      <td>LT</td>\n",
       "      <td>18940109</td>\n",
       "      <td>No. 11. When chemistry had finished _ shaping;...</td>\n",
       "      <td>True</td>\n",
       "      <td>[chemistry, finished, shaping, stuff, physical...</td>\n",
       "      <td>[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1...</td>\n",
       "      <td>[(0, 0.037070735571766454), (1, 0.041171491974...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT_18940115_ARTICLE5</th>\n",
       "      <td>THE THEORY OF EVOLUTION.</td>\n",
       "      <td>[SIGNIFICANT RUDIMENTS. [BY W.G.P.] No. lII.' ...</td>\n",
       "      <td>LT</td>\n",
       "      <td>18940115</td>\n",
       "      <td>SIGNIFICANT RUDIMENTS. [BY W.G.P.] No. lII.' '...</td>\n",
       "      <td>True</td>\n",
       "      <td>[significant, consideration, various, evidence...</td>\n",
       "      <td>[(1, 1), (7, 2), (17, 1), (24, 1), (31, 1), (3...</td>\n",
       "      <td>[(1, 0.03877920363299661), (7, 0.0474379255522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT_18940129_ARTICLE48</th>\n",
       "      <td>THE THEORY OF EVOLUTION.</td>\n",
       "      <td>[A CHANGED WORLD. [BY W.G.P.] No. V. The bitte...</td>\n",
       "      <td>LT</td>\n",
       "      <td>18940129</td>\n",
       "      <td>A CHANGED WORLD. [BY W.G.P.] No. V. The bitter...</td>\n",
       "      <td>True</td>\n",
       "      <td>[world, bitter, controversy, rang, round, orig...</td>\n",
       "      <td>[(3, 1), (4, 1), (6, 1), (12, 1), (18, 1), (23...</td>\n",
       "      <td>[(3, 0.039525783600009204), (4, 0.043022224916...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT_18940219_ARTICLE18</th>\n",
       "      <td>HERESY.</td>\n",
       "      <td>[TO THE EDITOR. Sir,— The action of the Presby...</td>\n",
       "      <td>LT</td>\n",
       "      <td>18940219</td>\n",
       "      <td>TO THE EDITOR. Sir,— The action of the Presbyt...</td>\n",
       "      <td>True</td>\n",
       "      <td>[editor, sir, action, assembly, rev, exercise,...</td>\n",
       "      <td>[(70, 1), (84, 2), (96, 2), (342, 1), (391, 1)...</td>\n",
       "      <td>[(70, 0.06050284829925989), (84, 0.12139272470...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT_18940219_ARTICLE24</th>\n",
       "      <td>REV JAMES GIBB ON CHRISTIAN DUTY.</td>\n",
       "      <td>[At St Andrew’s Presbyterian Church, yesterday...</td>\n",
       "      <td>LT</td>\n",
       "      <td>18940219</td>\n",
       "      <td>At St Andrew’s Presbyterian Church, yesterday ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[church, yesterday, forenoon, rev, one, church...</td>\n",
       "      <td>[(69, 1), (70, 1), (83, 1), (84, 2), (85, 1), ...</td>\n",
       "      <td>[(69, 0.04511879612777872), (70, 0.05041281137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ODT_18771031_ARTICLE30</th>\n",
       "      <td>THE INDIAN FAMINE.</td>\n",
       "      <td>[TO THE TJDITOR. Sir—l think I have_ fair caus...</td>\n",
       "      <td>ODT</td>\n",
       "      <td>18771031</td>\n",
       "      <td>TO THE TJDITOR. Sir—l think I have_ fair cause...</td>\n",
       "      <td>True</td>\n",
       "      <td>[sir, think, fair, cause, complaint, matter, d...</td>\n",
       "      <td>[(21, 1), (53, 1), (147, 1), (274, 1), (276, 1...</td>\n",
       "      <td>[(21, 0.07691984333370662), (53, 0.07667630373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ODT_18771107_ARTICLE32</th>\n",
       "      <td>POPULAR CULTURE.</td>\n",
       "      <td>[The. discourse of Mi* J^hn M &gt;r!ev on \" I'opu...</td>\n",
       "      <td>ODT</td>\n",
       "      <td>18771107</td>\n",
       "      <td>The. discourse of Mi* J^hn M &gt;r!ev on \" I'opul...</td>\n",
       "      <td>True</td>\n",
       "      <td>[discourse, urn, special, pro, method, cation,...</td>\n",
       "      <td>[(76, 1), (208, 1), (245, 1), (332, 1), (348, ...</td>\n",
       "      <td>[(76, 0.08702171966396995), (208, 0.1061276437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ODT_18790115_ARTICLE20</th>\n",
       "      <td>MR BRIGHT AND THE ELDERS. TO THE EDITOR.</td>\n",
       "      <td>[Sib,—However objectionable Mr Bright's title ...</td>\n",
       "      <td>ODT</td>\n",
       "      <td>18790115</td>\n",
       "      <td>Sib,—However objectionable Mr Bright's title m...</td>\n",
       "      <td>True</td>\n",
       "      <td>[sib, however, objectionable, title, may, subs...</td>\n",
       "      <td>[(59, 1), (125, 1), (221, 1), (369, 1), (469, ...</td>\n",
       "      <td>[(59, 0.13881791195587193), (125, 0.0952330491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ODT_18790118_ARTICLE23</th>\n",
       "      <td>UNTITLED</td>\n",
       "      <td>[Sir,—Before the public can fairly under stand...</td>\n",
       "      <td>ODT</td>\n",
       "      <td>18790118</td>\n",
       "      <td>Sir,—Before the public can fairly under stand ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[sir, public, fairly, stand, position, taken, ...</td>\n",
       "      <td>[(27, 1), (49, 1), (50, 1), (81, 1), (116, 1),...</td>\n",
       "      <td>[(27, 0.10105029797602266), (49, 0.07671554843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ODT_18790121_ARTICLE17</th>\n",
       "      <td>THE BIBLE SCHOOLS. TO THE EDITOR.</td>\n",
       "      <td>[Sia,—lt may not be out of place, in the prese...</td>\n",
       "      <td>ODT</td>\n",
       "      <td>18790121</td>\n",
       "      <td>Sia,—lt may not be out of place, in the presen...</td>\n",
       "      <td>True</td>\n",
       "      <td>[may, place, present, respecting, give, man, c...</td>\n",
       "      <td>[(8, 1), (57, 1), (71, 1), (276, 1), (505, 1),...</td>\n",
       "      <td>[(8, 0.09027143359096294), (57, 0.094443430647...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10013 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           Title  \\\n",
       "LT_18940109_ARTICLE7                  THE TASK OF THE BIOLOGIST.   \n",
       "LT_18940115_ARTICLE5                    THE THEORY OF EVOLUTION.   \n",
       "LT_18940129_ARTICLE48                   THE THEORY OF EVOLUTION.   \n",
       "LT_18940219_ARTICLE18                                    HERESY.   \n",
       "LT_18940219_ARTICLE24          REV JAMES GIBB ON CHRISTIAN DUTY.   \n",
       "...                                                          ...   \n",
       "ODT_18771031_ARTICLE30                        THE INDIAN FAMINE.   \n",
       "ODT_18771107_ARTICLE32                          POPULAR CULTURE.   \n",
       "ODT_18790115_ARTICLE20  MR BRIGHT AND THE ELDERS. TO THE EDITOR.   \n",
       "ODT_18790118_ARTICLE23                                  UNTITLED   \n",
       "ODT_18790121_ARTICLE17         THE BIBLE SCHOOLS. TO THE EDITOR.   \n",
       "\n",
       "                                                                     Text  \\\n",
       "LT_18940109_ARTICLE7    [No. 11. When chemistry had finished _ shaping...   \n",
       "LT_18940115_ARTICLE5    [SIGNIFICANT RUDIMENTS. [BY W.G.P.] No. lII.' ...   \n",
       "LT_18940129_ARTICLE48   [A CHANGED WORLD. [BY W.G.P.] No. V. The bitte...   \n",
       "LT_18940219_ARTICLE18   [TO THE EDITOR. Sir,— The action of the Presby...   \n",
       "LT_18940219_ARTICLE24   [At St Andrew’s Presbyterian Church, yesterday...   \n",
       "...                                                                   ...   \n",
       "ODT_18771031_ARTICLE30  [TO THE TJDITOR. Sir—l think I have_ fair caus...   \n",
       "ODT_18771107_ARTICLE32  [The. discourse of Mi* J^hn M >r!ev on \" I'opu...   \n",
       "ODT_18790115_ARTICLE20  [Sib,—However objectionable Mr Bright's title ...   \n",
       "ODT_18790118_ARTICLE23  [Sir,—Before the public can fairly under stand...   \n",
       "ODT_18790121_ARTICLE17  [Sia,—lt may not be out of place, in the prese...   \n",
       "\n",
       "                       Newspaper      Date  \\\n",
       "LT_18940109_ARTICLE7          LT  18940109   \n",
       "LT_18940115_ARTICLE5          LT  18940115   \n",
       "LT_18940129_ARTICLE48         LT  18940129   \n",
       "LT_18940219_ARTICLE18         LT  18940219   \n",
       "LT_18940219_ARTICLE24         LT  18940219   \n",
       "...                          ...       ...   \n",
       "ODT_18771031_ARTICLE30       ODT  18771031   \n",
       "ODT_18771107_ARTICLE32       ODT  18771107   \n",
       "ODT_18790115_ARTICLE20       ODT  18790115   \n",
       "ODT_18790118_ARTICLE23       ODT  18790118   \n",
       "ODT_18790121_ARTICLE17       ODT  18790121   \n",
       "\n",
       "                                                           Text as String  \\\n",
       "LT_18940109_ARTICLE7    No. 11. When chemistry had finished _ shaping;...   \n",
       "LT_18940115_ARTICLE5    SIGNIFICANT RUDIMENTS. [BY W.G.P.] No. lII.' '...   \n",
       "LT_18940129_ARTICLE48   A CHANGED WORLD. [BY W.G.P.] No. V. The bitter...   \n",
       "LT_18940219_ARTICLE18   TO THE EDITOR. Sir,— The action of the Presbyt...   \n",
       "LT_18940219_ARTICLE24   At St Andrew’s Presbyterian Church, yesterday ...   \n",
       "...                                                                   ...   \n",
       "ODT_18771031_ARTICLE30  TO THE TJDITOR. Sir—l think I have_ fair cause...   \n",
       "ODT_18771107_ARTICLE32  The. discourse of Mi* J^hn M >r!ev on \" I'opul...   \n",
       "ODT_18790115_ARTICLE20  Sib,—However objectionable Mr Bright's title m...   \n",
       "ODT_18790118_ARTICLE23  Sir,—Before the public can fairly under stand ...   \n",
       "ODT_18790121_ARTICLE17  Sia,—lt may not be out of place, in the presen...   \n",
       "\n",
       "                        Religion (pred)  \\\n",
       "LT_18940109_ARTICLE7               True   \n",
       "LT_18940115_ARTICLE5               True   \n",
       "LT_18940129_ARTICLE48              True   \n",
       "LT_18940219_ARTICLE18              True   \n",
       "LT_18940219_ARTICLE24              True   \n",
       "...                                 ...   \n",
       "ODT_18771031_ARTICLE30             True   \n",
       "ODT_18771107_ARTICLE32             True   \n",
       "ODT_18790115_ARTICLE20             True   \n",
       "ODT_18790118_ARTICLE23             True   \n",
       "ODT_18790121_ARTICLE17             True   \n",
       "\n",
       "                                                                Tokenised  \\\n",
       "LT_18940109_ARTICLE7    [chemistry, finished, shaping, stuff, physical...   \n",
       "LT_18940115_ARTICLE5    [significant, consideration, various, evidence...   \n",
       "LT_18940129_ARTICLE48   [world, bitter, controversy, rang, round, orig...   \n",
       "LT_18940219_ARTICLE18   [editor, sir, action, assembly, rev, exercise,...   \n",
       "LT_18940219_ARTICLE24   [church, yesterday, forenoon, rev, one, church...   \n",
       "...                                                                   ...   \n",
       "ODT_18771031_ARTICLE30  [sir, think, fair, cause, complaint, matter, d...   \n",
       "ODT_18771107_ARTICLE32  [discourse, urn, special, pro, method, cation,...   \n",
       "ODT_18790115_ARTICLE20  [sib, however, objectionable, title, may, subs...   \n",
       "ODT_18790118_ARTICLE23  [sir, public, fairly, stand, position, taken, ...   \n",
       "ODT_18790121_ARTICLE17  [may, place, present, respecting, give, man, c...   \n",
       "\n",
       "                                                                      BOW  \\\n",
       "LT_18940109_ARTICLE7    [(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1...   \n",
       "LT_18940115_ARTICLE5    [(1, 1), (7, 2), (17, 1), (24, 1), (31, 1), (3...   \n",
       "LT_18940129_ARTICLE48   [(3, 1), (4, 1), (6, 1), (12, 1), (18, 1), (23...   \n",
       "LT_18940219_ARTICLE18   [(70, 1), (84, 2), (96, 2), (342, 1), (391, 1)...   \n",
       "LT_18940219_ARTICLE24   [(69, 1), (70, 1), (83, 1), (84, 2), (85, 1), ...   \n",
       "...                                                                   ...   \n",
       "ODT_18771031_ARTICLE30  [(21, 1), (53, 1), (147, 1), (274, 1), (276, 1...   \n",
       "ODT_18771107_ARTICLE32  [(76, 1), (208, 1), (245, 1), (332, 1), (348, ...   \n",
       "ODT_18790115_ARTICLE20  [(59, 1), (125, 1), (221, 1), (369, 1), (469, ...   \n",
       "ODT_18790118_ARTICLE23  [(27, 1), (49, 1), (50, 1), (81, 1), (116, 1),...   \n",
       "ODT_18790121_ARTICLE17  [(8, 1), (57, 1), (71, 1), (276, 1), (505, 1),...   \n",
       "\n",
       "                                                                   TF-IDF  \n",
       "LT_18940109_ARTICLE7    [(0, 0.037070735571766454), (1, 0.041171491974...  \n",
       "LT_18940115_ARTICLE5    [(1, 0.03877920363299661), (7, 0.0474379255522...  \n",
       "LT_18940129_ARTICLE48   [(3, 0.039525783600009204), (4, 0.043022224916...  \n",
       "LT_18940219_ARTICLE18   [(70, 0.06050284829925989), (84, 0.12139272470...  \n",
       "LT_18940219_ARTICLE24   [(69, 0.04511879612777872), (70, 0.05041281137...  \n",
       "...                                                                   ...  \n",
       "ODT_18771031_ARTICLE30  [(21, 0.07691984333370662), (53, 0.07667630373...  \n",
       "ODT_18771107_ARTICLE32  [(76, 0.08702171966396995), (208, 0.1061276437...  \n",
       "ODT_18790115_ARTICLE20  [(59, 0.13881791195587193), (125, 0.0952330491...  \n",
       "ODT_18790118_ARTICLE23  [(27, 0.10105029797602266), (49, 0.07671554843...  \n",
       "ODT_18790121_ARTICLE17  [(8, 0.09027143359096294), (57, 0.094443430647...  \n",
       "\n",
       "[10013 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_corpus.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_corpus.items.to_pickle('pickles/rel_v2_df_with_bow_and_tfidf.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes over time? - I don't think this is helping me. Need some more non-philosophy as a background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse = corpus2csc(rel_corpus.items['BOW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = pd.DataFrame.sparse.from_spmatrix(sparse)\n",
    "del sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.index = rel_corpus.dictionary.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>10003</th>\n",
       "      <th>10004</th>\n",
       "      <th>10005</th>\n",
       "      <th>10006</th>\n",
       "      <th>10007</th>\n",
       "      <th>10008</th>\n",
       "      <th>10009</th>\n",
       "      <th>10010</th>\n",
       "      <th>10011</th>\n",
       "      <th>10012</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accomplished</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accordingly</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ail</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judices</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geologically</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heedless</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>referee</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renown</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11593 rows × 10013 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0      1      2      3      4      5      6      7      8      \\\n",
       "accomplished    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "accordingly     1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "act             1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "actual          2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "ail             1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...             ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "judices         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "geologically    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "heedless        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "referee         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "renown          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "              9      ...  10003  10004  10005  10006  10007  10008  10009  \\\n",
       "accomplished    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "accordingly     0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "act             1.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "actual          0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "ail             0.0  ...    0.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...             ...  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "judices         0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "geologically    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "heedless        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "referee         0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "renown          0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "              10010  10011  10012  \n",
       "accomplished    0.0    0.0    0.0  \n",
       "accordingly     0.0    0.0    0.0  \n",
       "act             0.0    0.0    0.0  \n",
       "actual          0.0    0.0    0.0  \n",
       "ail             0.0    0.0    0.0  \n",
       "...             ...    ...    ...  \n",
       "judices         0.0    0.0    0.0  \n",
       "geologically    0.0    0.0    0.0  \n",
       "heedless        0.0    0.0    0.0  \n",
       "referee         0.0    0.0    0.0  \n",
       "renown          0.0    0.0    0.0  \n",
       "\n",
       "[11593 rows x 10013 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.to_pickle('pickles/dtm_rel_v2_BOW_11kwords.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_df = dtm.dot(dtm.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_df.to_pickle('pickles/ttm_rel_v2_BOW_11kwords.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accomplished</th>\n",
       "      <th>accordingly</th>\n",
       "      <th>act</th>\n",
       "      <th>actual</th>\n",
       "      <th>ail</th>\n",
       "      <th>alike</th>\n",
       "      <th>alive</th>\n",
       "      <th>animal</th>\n",
       "      <th>apart</th>\n",
       "      <th>appearance</th>\n",
       "      <th>...</th>\n",
       "      <th>charmingly</th>\n",
       "      <th>ordinal</th>\n",
       "      <th>cane</th>\n",
       "      <th>moio</th>\n",
       "      <th>mime</th>\n",
       "      <th>judices</th>\n",
       "      <th>geologically</th>\n",
       "      <th>heedless</th>\n",
       "      <th>referee</th>\n",
       "      <th>renown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accomplished</th>\n",
       "      <td>362.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accordingly</th>\n",
       "      <td>13.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act</th>\n",
       "      <td>89.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2497.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ail</th>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judices</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geologically</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heedless</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>referee</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renown</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11593 rows × 11593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              accomplished  accordingly     act  actual    ail  alike  alive  \\\n",
       "accomplished         362.0         13.0    89.0    22.0   17.0   32.0   18.0   \n",
       "accordingly           13.0        207.0    84.0    30.0   21.0   27.0    5.0   \n",
       "act                   89.0         84.0  2497.0   148.0   95.0  175.0   51.0   \n",
       "actual                22.0         30.0   148.0   724.0   26.0   40.0   19.0   \n",
       "ail                   17.0         21.0    95.0    26.0  446.0   44.0   17.0   \n",
       "...                    ...          ...     ...     ...    ...    ...    ...   \n",
       "judices                0.0          0.0     3.0     2.0    0.0    1.0    2.0   \n",
       "geologically           2.0          0.0     7.0     4.0    1.0    3.0    3.0   \n",
       "heedless               1.0          0.0     1.0     0.0    0.0    5.0    0.0   \n",
       "referee                0.0          0.0     2.0     0.0    1.0    0.0    3.0   \n",
       "renown                 0.0          0.0     3.0     0.0    0.0    5.0    0.0   \n",
       "\n",
       "              animal  apart  appearance  ...  charmingly  ordinal  cane  moio  \\\n",
       "accomplished   105.0   33.0        34.0  ...         1.0      0.0   0.0   3.0   \n",
       "accordingly     76.0   17.0        27.0  ...         2.0      1.0   0.0   0.0   \n",
       "act            568.0  140.0       114.0  ...         2.0      3.0   1.0   9.0   \n",
       "actual         286.0   56.0        67.0  ...         2.0      0.0   0.0   0.0   \n",
       "ail            114.0   53.0        36.0  ...         0.0      2.0   1.0   2.0   \n",
       "...              ...    ...         ...  ...         ...      ...   ...   ...   \n",
       "judices          2.0    3.0         0.0  ...         0.0      0.0   0.0   0.0   \n",
       "geologically    40.0    0.0         3.0  ...         0.0      0.0   0.0   0.0   \n",
       "heedless         0.0    0.0         2.0  ...         0.0      0.0   0.0   0.0   \n",
       "referee          0.0    0.0         1.0  ...         0.0      0.0   0.0   0.0   \n",
       "renown           3.0    2.0         1.0  ...         0.0      0.0   1.0   0.0   \n",
       "\n",
       "              mime  judices  geologically  heedless  referee  renown  \n",
       "accomplished   2.0      0.0           2.0       1.0      0.0     0.0  \n",
       "accordingly    0.0      0.0           0.0       0.0      0.0     0.0  \n",
       "act            7.0      3.0           7.0       1.0      2.0     3.0  \n",
       "actual         7.0      2.0           4.0       0.0      0.0     0.0  \n",
       "ail            1.0      0.0           1.0       0.0      1.0     0.0  \n",
       "...            ...      ...           ...       ...      ...     ...  \n",
       "judices        0.0     13.0           0.0       0.0      0.0     0.0  \n",
       "geologically   1.0      0.0          10.0       0.0      0.0     0.0  \n",
       "heedless       0.0      0.0           0.0      10.0      0.0     0.0  \n",
       "referee        0.0      0.0           0.0       0.0     12.0     0.0  \n",
       "renown         0.0      0.0           0.0       0.0      0.0    19.0  \n",
       "\n",
       "[11593 rows x 11593 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://tm4ss.github.io/docs/Tutorial_5_Co-occurrence.html\n",
    "def dice_coocs(term, dtm, ttm, num_coocs):\n",
    "    \"\"\"Return num_coocs with dice statistics given search term\n",
    "    document-term matrix and term-term matrix. Return as \n",
    "    pandas series with terms as indices and significances as values..\n",
    "    ttm and dtm are pandas dataframes.\"\"\"\n",
    "    #num_documents = len(dtm.columns)\n",
    "    all_term_occurrences = dtm.sum(axis=1)\n",
    "    term_occurrences = all_term_occurrences[term]\n",
    "    cooccurrences = ttm.loc[term]\n",
    "    dicesig = 2 * cooccurrences / (term_occurrences + all_term_occurrences)\n",
    "    dicesig = dicesig.sort_values(ascending=False)[0:num_coocs]\n",
    "    return dicesig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicesig = 2 * cooccurrences / (term_occurrences + all_term_occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dicesig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicesig.sort_values(ascending=False)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_coocs('philosophy', binary_dtm, tt_df, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NL_helpers.log_dice_coocs('infinite', dtm, tt_df, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "philo_cooc = dice_coocs('philosophy', binary_dtm, tt_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "philo_network = NL_helpers.network_dataframe(\n",
    "    term='philosophy', \n",
    "    stat='ml', \n",
    "    dtm=dtm,\n",
    "    ttm=tt_df,\n",
    "    num_coocs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "philo_network_df = pd.DataFrame(data=philo_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = {}\n",
    "for item in philo_cooc.iteritems():\n",
    "    from_list = network.get('source', [])\n",
    "    from_list.append('philosophy')\n",
    "    network['source'] = from_list\n",
    "    to_list = network.get('target', [])\n",
    "    to_list.append(item[0])\n",
    "    network['target'] = to_list\n",
    "    weight_list = network.get('weight', [])\n",
    "    weight_list.append(item[1])\n",
    "    network['weight'] = weight_list\n",
    "    \n",
    "    item_coocs = dice_coocs(item[0], binary_dtm, tt_df, 10)\n",
    "    for sub_item in item_coocs.iteritems():\n",
    "        if item[0] != sub_item[0]:\n",
    "            from_list = network.get('source', [])\n",
    "            from_list.append(item[0])\n",
    "            network['source'] = from_list\n",
    "            to_list = network.get('target', [])\n",
    "            to_list.append(sub_item[0])\n",
    "            network['target'] = to_list\n",
    "            weight_list = network.get('weight', [])\n",
    "            weight_list.append(sub_item[1])\n",
    "            network['weight'] = weight_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df = pd.DataFrame(data=network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.convert_matrix.from_pandas_edgelist(philo_network_df, edge_attr='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = G.edges()\n",
    "weights = [np.exp(G[u][v]['weight']) * 0.01 for u,v in edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = nx.degree(G)\n",
    "sizes = [(d[node]+1) * 100 for node in G.nodes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = nx.drawing.layout.spring_layout(G, k=1/np.sqrt(len(G.nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "# Visualize graph components\n",
    "nx.draw_networkx_edges(G, layout, alpha=0.5, width=weights, edge_color=\"m\")\n",
    "nx.draw_networkx_nodes(G, layout, node_size=sizes, node_color=\"#210070\", alpha=0.9)\n",
    "label_options = {\"ec\": \"k\", \"fc\": \"white\", \"alpha\": 0.7}\n",
    "labels = nx.draw_networkx_labels(G, layout, font_size=11, bbox=label_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "philo_net = NL_helpers.network_dash(\n",
    "    term='philosophy', \n",
    "    stat='log dice', \n",
    "    dtm=dtm,\n",
    "    ttm=tt_df,\n",
    "    num_coocs=25,\n",
    "    sec_coocs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "philo_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "app = JupyterDash(__name__)\n",
    "\n",
    "philo_cytoscape = cyto.Cytoscape(\n",
    "        id='philosophy-network',\n",
    "        minZoom=1,\n",
    "        layout={'name': 'cose'},\n",
    "        style={'width': '100%', 'height': '800px'},\n",
    "        elements=philo_net,\n",
    "        stylesheet=[\n",
    "            {\n",
    "                'selector': 'edge',\n",
    "                'style': {\n",
    "                    'width': 'mapData(weight, 3, 6, 1, 3)',\n",
    "                    'line-color': 'silver'\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'selector': 'node',\n",
    "                'style': {\n",
    "                    'content': 'data(label)',\n",
    "                    'width': 'mapData(size, 1, 10, 10, 20)',\n",
    "                    'height': 'mapData(size, 1, 10, 10, 20)'\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'selector': 'label',\n",
    "                'style': {\n",
    "                    'font-size': 6,\n",
    "                    'text-valign': 'center',\n",
    "                    'text-background-color': 'white',\n",
    "                    'text-background-opacity': 0.6,\n",
    "                    'text-background-padding': 1,\n",
    "                    'text-border-color': 'black',\n",
    "                    'text-border-opacity': 1,\n",
    "                    'text-border-width': 0.5\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H2(\"Cooccurence Networks (BOW)\"),\n",
    "    html.P(\"Search Term:\"),\n",
    "    dcc.Input(\n",
    "        id='search-term',\n",
    "        type='text',\n",
    "        value='philosophy'\n",
    "    ),\n",
    "    html.P(\"Statistic:\"),\n",
    "    dcc.Dropdown(\n",
    "        id='stat-choice',\n",
    "        options=[\n",
    "            {'label': 'Mutual likelihood', 'value': 'ml'},\n",
    "            {'label': 'Log Dice', 'value': 'log dice'}\n",
    "        ],\n",
    "        value='ml'\n",
    "    ),\n",
    "    html.Button('Submit', id='submit-val', n_clicks=0),\n",
    "    philo_cytoscape\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output(component_id='philosophy-network', component_property='elements'),\n",
    "    Input(component_id='submit-val', component_property='n_clicks'),\n",
    "    State(component_id='stat-choice', component_property='value'),\n",
    "    State(component_id='search-term', component_property='value'),\n",
    ")\n",
    "def update_network_stat(n_clicks, stat_value, search_value):\n",
    "    network = NL_helpers.network_dash(\n",
    "        term=search_value, \n",
    "        stat=stat_value, \n",
    "        dtm=dtm,\n",
    "        ttm=tt_df,\n",
    "        num_coocs=10,\n",
    "        sec_coocs=5\n",
    "    )\n",
    "    return network \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, mode='inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some candidate keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NL_helpers.interactive_text_search(philoso_df, \"[Mm]ill\\'s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NL_helpers.interactive_text_search(philoso_df, '[Hh]artley')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expansion of Philosophy Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proposed Classification Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: the topic model code again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convenient moment for running a topic model on the philosophy corpus came up. Here is a model using the full philosophy set dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(philoso_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_model = LdaMulticore(\n",
    "    philo_corpus,\n",
    "    num_topics= 200,\n",
    "    workers = 15,\n",
    "    chunksize = 220,\n",
    "    id2word=philo_corpus.dictionary,\n",
    "    iterations = 500,\n",
    "    passes = 25,\n",
    "    eval_every = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = set(['phil'])\n",
    "dog.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = [1, 2, 3]\n",
    "cat = [4, 5, 6]\n",
    "dog + cat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
